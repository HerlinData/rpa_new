# ğŸš€ RPA New - GuÃ­a Paso a Paso

Este proyecto usa **Nivel 2 POO** (Herencia + Polimorfismo) - el balance perfecto entre simplicidad y reutilizaciÃ³n.

## ğŸ“ Estructura del Proyecto

```
rpa_new/
â”œâ”€â”€ config/                 # PASO 1: ConfiguraciÃ³n
â”‚   â”œâ”€â”€ settings.py        # ConfiguraciÃ³n centralizada
â”‚   â””â”€â”€ .env.example       # Plantilla para credenciales
â”‚
â”œâ”€â”€ core/                   # PASO 2: Componentes core
â”‚   â””â”€â”€ database.py        # ConexiÃ³n a SQL Server
â”‚
â”œâ”€â”€ scrapers/              # PASO 3-4: Scrapers
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â””â”€â”€ base_scraper.py      # Clase base (Template Method)
â”‚   â””â”€â”€ implementaciones/
â”‚       â””â”€â”€ salesys_scraper.py   # Ejemplo de implementaciÃ³n
â”‚
â”œâ”€â”€ tasks/                  # PASO 5: OrquestaciÃ³n (opcional)
â”‚   â””â”€â”€ task_interface.py  # Tareas que ejecutan scrapers
â”‚
â”œâ”€â”€ utils/                  # PASO 6: Utilidades (opcional)
â”‚   â””â”€â”€ selenium_helpers.py
â”‚
â”œâ”€â”€ main.py                 # PASO 7: Punto de entrada
â””â”€â”€ requirements.txt        # Dependencias
```

---

## ğŸ¯ FilosofÃ­a del Proyecto

### âœ… QuÃ© ES este proyecto:
- **Nivel 2 POO**: Herencia + Polimorfismo sin sobre-ingenierÃ­a
- **Template Method Pattern**: Flujo comÃºn en clase base, detalles en subclases
- **DRY**: Don't Repeat Yourself
- **KISS**: Keep It Simple, Stupid

### âŒ QuÃ© NO es:
- NO es arquitectura SOLID completa (eso es Nivel 3, sobre-ingeniado)
- NO tiene Factories, Registry, ni Dependency Injection
- NO tiene interfaces abstractas innecesarias

---

## ğŸ“š GuÃ­a de ImplementaciÃ³n Paso a Paso

### PASO 1: Configurar el proyecto

1. **Instalar dependencias:**
   ```bash
   cd rpa_new
   pip install -r requirements.txt
   ```

2. **Crear archivo .env:**
   ```bash
   cp config/.env.example .env
   # Editar .env con tus credenciales reales
   ```

3. **Verificar settings.py:**
   - Abre `config/settings.py`
   - Lee los comentarios
   - Ajusta rutas si es necesario

---

### PASO 2: Implementar DatabaseConnection

1. **Abre `core/database.py`**
2. **Busca los `TODO` y completa:**
   - `__init__`: Guardar parÃ¡metros de conexiÃ³n
   - `connect()`: Crear engine de SQLAlchemy
   - `query()`: Ejecutar SELECT
   - `insert_dataframe()`: Insertar DataFrame
   - `delete_and_insert()`: DELETE + INSERT

3. **Ejemplo de implementaciÃ³n:**
   ```python
   def __init__(self, server, database, user=None, password=None):
       self.server = server
       self.database = database
       self.engine = None
       self.connect()

   def connect(self):
       conn_str = f"mssql+pyodbc://{self.server}/{self.database}?driver=ODBC+Driver+17+for+SQL+Server"
       self.engine = create_engine(conn_str)

   def query(self, sql):
       return pd.read_sql(sql, self.engine)
   ```

4. **Probar:**
   ```python
   from core.database import DatabaseConnection
   db = DatabaseConnection("servidor", "bd")
   df = db.query("SELECT TOP 5 * FROM tabla")
   print(df)
   ```

---

### PASO 3: Entender BaseScraper

1. **Abre `scrapers/base/base_scraper.py`**
2. **Lee el flujo en `ejecutar()`:**
   ```python
   def ejecutar(self):
       self.configurar_driver()  # Configura Chrome
       self.login()              # Login (abstracto)
       self.navegar_a_reporte()  # Navega al reporte (abstracto)
       ruta = self.descargar_archivo()  # Descarga (abstracto)
       df = self.procesar_datos(ruta)   # Procesa (abstracto)
       self.guardar_en_bd(df)    # Guarda en BD (opcional)
       self.cerrar()             # Cierra navegador
   ```

3. **Completa los mÃ©todos concretos:**
   - `configurar_driver()`: Configurar Selenium WebDriver
   - `cerrar()`: Cerrar navegador

4. **NO toques los mÃ©todos `@abstractmethod`** - esos se implementan en las subclases

---

### PASO 4: Crear tu primer Scraper (Herencia)

Usaremos `SalesysScraper` como ejemplo.

1. **Abre `scrapers/implementaciones/salesys_scraper.py`**

2. **Observa cÃ³mo hereda de BaseScraper:**
   ```python
   class SalesysScraper(BaseScraper):
       def __init__(self, reporte_nombre):
           super().__init__(platform_name="Salesys")
           self.reporte_nombre = reporte_nombre
   ```

3. **Implementa los mÃ©todos abstractos uno por uno:**

   **a) `login()`:**
   ```python
   def login(self):
       self.driver.get("https://salesys.example.com/login")
       self.driver.find_element(By.ID, "username").send_keys(SALESYS_USER)
       self.driver.find_element(By.ID, "password").send_keys(SALESYS_PASS)
       self.driver.find_element(By.ID, "login-btn").click()
       time.sleep(3)
   ```

   **b) `navegar_a_reporte()`:**
   ```python
   def navegar_a_reporte(self):
       self.driver.find_element(By.LINK_TEXT, "Reportes").click()
       self.driver.find_element(By.LINK_TEXT, self.reporte_nombre).click()
       time.sleep(2)
   ```

   **c) `descargar_archivo()`:**
   ```python
   def descargar_archivo(self):
       self.driver.find_element(By.ID, "btn-download").click()
       time.sleep(5)
       return DOWNLOADS_DIR / f"{self.reporte_nombre}.xlsx"
   ```

   **d) `procesar_datos()`:**
   ```python
   def procesar_datos(self, ruta_archivo):
       df = pd.read_excel(ruta_archivo)
       df = df.dropna()
       # Aplicar transformaciones especÃ­ficas
       return df
   ```

4. **Probar el scraper:**
   ```python
   scraper = SalesysScraper("RGA")
   df = scraper.ejecutar()  # Usa el flujo de BaseScraper automÃ¡ticamente
   ```

---

### PASO 5: Crear mÃ¡s Scrapers (Polimorfismo)

Ahora crea scrapers para otras plataformas siguiendo el mismo patrÃ³n:

1. **GenesysScraper:**
   ```bash
   # Crear archivo
   touch scrapers/implementaciones/genesys_scraper.py
   ```

2. **Copiar estructura de SalesysScraper**

3. **Implementar mÃ©todos especÃ­ficos de Genesys:**
   - `login()` â†’ Login de Genesys
   - `navegar_a_reporte()` â†’ NavegaciÃ³n especÃ­fica
   - `descargar_archivo()` â†’ Descarga de Genesys
   - `procesar_datos()` â†’ Procesamiento especÃ­fico

4. **El flujo `ejecutar()` es el mismo** - heredado de BaseScraper

---

### PASO 6: Orquestar con Tasks (Opcional)

Si necesitas ejecutar mÃºltiples scrapers:

1. **Abre `tasks/task_interface.py`**

2. **Implementa `SalesysReportTask.execute()`:**
   ```python
   def execute(self):
       from scrapers.implementaciones.salesys_scraper import SalesysScraper

       scraper = SalesysScraper(self.reporte_nombre)
       df = scraper.ejecutar()

       return {
           'status': 'success',
           'reporte': self.reporte_nombre,
           'registros': len(df),
           'data': df
       }
   ```

3. **Crear mÃ¡s tasks:**
   - `GenesysReportTask`
   - `ConsolidacionTask` (que combine varios scrapers)

---

### PASO 7: Ejecutar desde main.py

1. **Abre `main.py`**

2. **Implementa ejecuciÃ³n de tareas:**
   ```python
   def main():
       # Ejecutar Salesys RGA
       task_rga = SalesysReportTask("RGA")
       resultado_rga = task_rga.run()

       # Ejecutar Salesys NÃ³mina
       task_nomina = SalesysReportTask("Nomina")
       resultado_nomina = task_nomina.run()

       # Mostrar resumen
       print(f"RGA: {resultado_rga['registros']} registros")
       print(f"NÃ³mina: {resultado_nomina['registros']} registros")
   ```

3. **Ejecutar:**
   ```bash
   python main.py
   ```

---

## ğŸ“ Conceptos Clave

### 1. Template Method Pattern
```python
# BaseScraper define el FLUJO (template)
def ejecutar(self):
    self.login()              # â† Cada subclase implementa
    self.navegar_a_reporte()  # â† Cada subclase implementa
    self.descargar_archivo()  # â† Cada subclase implementa
```

### 2. Herencia
```python
# SalesysScraper HEREDA el flujo de BaseScraper
class SalesysScraper(BaseScraper):
    # Solo implementa los detalles especÃ­ficos
```

### 3. Polimorfismo
```python
# Puedes tratar todos los scrapers igual
scrapers = [
    SalesysScraper("RGA"),
    GenesysScraper("Ocupacion"),
    NavicatScraper("Reporte1")
]

for scraper in scrapers:
    scraper.ejecutar()  # Cada uno ejecuta su propia implementaciÃ³n
```

---

## ğŸ”„ ComparaciÃ³n con Proyecto Anterior

### âŒ Antes (RPA_/ - Nivel 3 SOLID):
- 80+ archivos para entender
- Factories, Registry, Interfaces abstractas
- DifÃ­cil de mantener para equipos pequeÃ±os

### âœ… Ahora (RPA_new/ - Nivel 2 POO):
- ~10 archivos principales
- Herencia simple + Template Method
- FÃ¡cil de entender y extender

---

## ğŸ“ Checklist de Progreso

- [ ] PASO 1: ConfiguraciÃ³n y .env
- [ ] PASO 2: DatabaseConnection implementado
- [ ] PASO 3: BaseScraper completado
- [ ] PASO 4: Primer scraper (Salesys) funcionando
- [ ] PASO 5: Segundo scraper (Genesys/otro)
- [ ] PASO 6: Tasks implementadas (opcional)
- [ ] PASO 7: main.py ejecutando todo

---

## ğŸš¨ Errores Comunes

1. **Olvidar llamar `super().__init__()`:**
   ```python
   # âŒ MAL
   def __init__(self):
       self.nombre = "Salesys"

   # âœ… BIEN
   def __init__(self):
       super().__init__(platform_name="Salesys")
   ```

2. **Sobreescribir `ejecutar()`:**
   ```python
   # âŒ MAL - NO sobreescribas ejecutar()
   def ejecutar(self):
       # cÃ³digo personalizado

   # âœ… BIEN - Solo implementa los mÃ©todos abstractos
   def login(self):
       # tu implementaciÃ³n
   ```

3. **Hardcodear credenciales:**
   ```python
   # âŒ MAL
   user = "mi_usuario"

   # âœ… BIEN
   from config.settings import SALESYS_USER
   ```

---

## ğŸ’¡ PrÃ³ximos Pasos

DespuÃ©s de completar los 7 pasos:

1. **Agregar mÃ¡s scrapers** usando el mismo patrÃ³n
2. **Agregar logging** para debugging
3. **Agregar manejo de errores** mÃ¡s robusto
4. **Agregar tests** (pytest) cuando sea necesario

---

## ğŸ“ Recursos

- **REFACTORING_PROGRESS.md**: Lecciones aprendidas del proyecto anterior
- **ARCHITECTURE.md**: ExplicaciÃ³n de la arquitectura (si existe)
- **Template Method Pattern**: [Refactoring Guru](https://refactoring.guru/design-patterns/template-method)

---

**Ãšltima actualizaciÃ³n:** 2025-12-12
**Nivel de complejidad:** Intermedio (Nivel 2 POO)
**Tiempo estimado:** Completar PASO 1-4 te da un scraper funcional
